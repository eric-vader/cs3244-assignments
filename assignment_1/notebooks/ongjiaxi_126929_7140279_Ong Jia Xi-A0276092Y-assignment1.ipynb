{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5fdf63-0a79-4490-aa8f-3669ba1a7f58",
   "metadata": {},
   "source": [
    "# Assignment 1: k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35168e77",
   "metadata": {},
   "source": [
    "Fill in your name and student ID here.\n",
    "- Name: Ong Jia Xi\n",
    "- Student ID: A0276092Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fadaa-a686-498a-b9c0-d56a6c8b591f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e120208",
   "metadata": {},
   "source": [
    "In this assignment, we'll implement KNN step-by-step:\n",
    "\n",
    "1. **Euclidean Distance:** Measure similarity between data points.\n",
    "2. **Find Neighbors:** Select the 'K' closest points to a query point.\n",
    "3. **Predict (Classification and Regression):** Use majority vote from neighbors and average of neighbors' values.\n",
    "4. **Build KNN Class:** Combine everything into a reusable class.\n",
    "5. **Practical**: Train a KNN classifier on the training dataset using scikit-learn.\n",
    "\n",
    "By the end, you'll understand how KNN works and how it makes predictions based on distance. Let’s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907f448",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e5041",
   "metadata": {},
   "source": [
    "1. Fill in your name and student ID at the top of the ipynb file.\n",
    "2. The parts you need to implement are clearly marked with the following:\n",
    "\n",
    "    ```\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "    ```\n",
    "\n",
    "    , and you must **ONLY** write your code in between the above two lines. \n",
    "3. **IMPORTANT**: Make sure that all of the cells are runnable and can compile without exception, even if the answer is incorrect. This will significantly help us in grading your solutions.\n",
    "3. For task 1 to 4, you are only allowed to use basic Python functions in your code (no `NumPy` or its equivalents), unless otherwise stated. You may reuse any functions you have defined earlier. If you are unsure whether a particular function is allowed, feel free to ask any of the TAs.\n",
    "4. For task 5, you may use the `scikit-learn` library.\n",
    "5. Your solutions will be evaluated against a set of hidden test cases to prevent hardcoding of the answer. You may assume that the test cases are always valid and does not require exception or input mismatch handling. Partial marks may be given for partially correct solutions\n",
    "\n",
    "### Submission Instructions\n",
    "Items to be submitted:\n",
    "* **This notebook, NAME-STUID-assignment1.ipynb**: This is where you fill in all your code. Replace \"NAME\" with your full name and \"STUID\" with your student ID, which starts with \"A\", e.g. `\"John Doe-A0123456X-assignment1.ipynb\"`\n",
    "\n",
    "Submit your assignment by **Sunday, 31 August 23:59** to Canvas. Points will be deducted late submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078789f1",
   "metadata": {},
   "source": [
    "## Task 1 - Compute Euclidean Distance [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef572c3-37d7-4cb1-a9b3-e3c5c35f2586",
   "metadata": {},
   "source": [
    "To find the nearest neighbors, we first need a distance measure to determine how **close** two data points are. \n",
    "\n",
    "A possible distance measure is **Euclidean distance**—the straight-line distance between points $\\mathbf{p} = [p_1, p_2, ..., p_m]$ and $\\mathbf{q} = [q_1, q_2, ..., q_m]$ in $m$ dimensions:\n",
    "\n",
    "$$\n",
    "d_\\text{euclidean}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{m} (p_i - q_i)^2}\n",
    "$$\n",
    "\n",
    "Implement the function calculating euclidean distance using `math.sqrt()`, without the use of `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea197b46-1d86-4dbd-8474-36d62b8291d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 1\n",
    "import math \n",
    "\n",
    "def euclidean_distance(vec_p, vec_q):\n",
    "    \"\"\"\n",
    "    TODO: Write a function to compute distance between two vectors.\n",
    "    Call the math.sqrt() function to compute the square root of the sum of squared differences.\n",
    "\n",
    "    Args:\n",
    "        vec_p: List or tuple p, with a list of m numbers\n",
    "        vec_q: List or tuple q, with a list of m numbers\n",
    "\n",
    "    Returns:\n",
    "        A float representing the Euclidean distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    distance = 0\n",
    "\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"   \n",
    "    if len(vec_p) == 0 or len(vec_q) == 0:\n",
    "        print('Please provide vector of correct dimension!')\n",
    "    if len(vec_p) != len(vec_q): \n",
    "        print('Vector dimension is inconsistent!')\n",
    "    \n",
    "    # Assume length of both vectors is consistent\n",
    "    v_len = len(vec_p)\n",
    "\n",
    "    # Track sum of squared difference\n",
    "    ssd = 0 \n",
    "    for i in range(v_len):\n",
    "        ssd += (vec_p[i] - vec_q[i]) ** 2 \n",
    "    \n",
    "    distance = math.sqrt(ssd)\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "# TESTCASES 1\n",
    "assert math.isclose(euclidean_distance([1, 2, 3], [4, 5, 6]), 5.196152422706632, rel_tol=1e-5)\n",
    "assert math.isclose(euclidean_distance([5.5, 5.5], [5.5, 5.5]), 0.0, rel_tol=1e-5)\n",
    "assert math.isclose(euclidean_distance([-6], [-6]), 0.0, rel_tol=1e-5)\n",
    "print('All test cases passed!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127cc23a",
   "metadata": {},
   "source": [
    "## Task 2 - Get the K Nearest Neighbors [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b419ad",
   "metadata": {},
   "source": [
    "Now that we can measure distance, let’s use that to find the ```k``` closest training points to a given test point. If there are multiple points with the same distance, we keep the ones that appear first in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82ccfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 2\n",
    "def get_k_nearest_neighbors(training_data, test_point, k):\n",
    "    \"\"\"\n",
    "    TODO: Return the k nearest neighbors to the test_point.\n",
    "\n",
    "    Args:\n",
    "        training_data: list of tuples [(feature_vector, label), ...]\n",
    "        test_point: list of numbers (the point we're classifying)\n",
    "        k: number of neighbors to consider\n",
    "        \n",
    "    Returns:\n",
    "        list of labels of the k nearest neighbors in the correct order\n",
    "    \"\"\"\n",
    "\n",
    "    k_neighbors = []\n",
    "    \n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"  \n",
    "    \n",
    "    # Compute all the distances of one test point to the other points in training_data\n",
    "    distances = []\n",
    "    for train_pt in training_data:\n",
    "        X_train = train_pt[0]\n",
    "        distances.append(euclidean_distance(test_point, X_train))\n",
    "\n",
    "    # Sort the distances + Handle tiebreaker naturally\n",
    "    distances = sorted(enumerate(distances), key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    # Get classification\n",
    "    pair = distances[:k]\n",
    "    for idx, _ in pair:\n",
    "        label = training_data[idx][1]\n",
    "        k_neighbors.append(label)\n",
    "\n",
    "    # Append the result into the list \n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    return k_neighbors\n",
    "\n",
    "# TESTCASES 2.1\n",
    "training_data = [\n",
    "    ([1, 2], 'A'),\n",
    "    ([2, 3], 'B'),\n",
    "    ([3, 4], 'A'),\n",
    "    ([5, 5], 'B')\n",
    "]\n",
    "\n",
    "assert get_k_nearest_neighbors(training_data, [1.5, 2.5], k=2) == ['A', 'B']\n",
    "assert get_k_nearest_neighbors(training_data, [4, 4], k=1) == ['A']\n",
    "assert get_k_nearest_neighbors(training_data, [0, 0], k=3) == ['A', 'B', 'A']\n",
    "print('All test cases passed!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f416626",
   "metadata": {},
   "source": [
    "## Task 3 - Prediction [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73ccfa",
   "metadata": {},
   "source": [
    "### Task 3.1 - Compute Majority Voting [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb1894",
   "metadata": {},
   "source": [
    "Once we have the `k` nearest neighbors, we need to decide the final label, which is the label that appears the most frequently. If there is a tie, return the label that appears first in the input list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d69d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 3.1\n",
    "def knn_majority_vote(neighbors):\n",
    "    \"\"\"\n",
    "    TODO: Return the most common label in neighbors.\n",
    "\n",
    "    Args:\n",
    "        neighbors: list of labels\n",
    "\n",
    "    Returns:\n",
    "        The label that appears most frequently\n",
    "        If there's a tie, return the label that appears first\n",
    "    \"\"\"\n",
    "    \n",
    "    most_common_label = None\n",
    "    \n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "    hash_set = {}\n",
    "    counter = 0\n",
    "\n",
    "    for neigh in neighbors:\n",
    "        if neigh not in hash_set:\n",
    "            hash_set[neigh] = 0\n",
    "        hash_set[neigh] += 1\n",
    "\n",
    "    possible_label = []\n",
    "    majority_count = max(list(hash_set.values()))\n",
    "    for k, v in hash_set.items():\n",
    "        if v == majority_count:\n",
    "            possible_label.append(k)\n",
    "    \n",
    "    if len(possible_label) == 1:\n",
    "        most_common_label = possible_label[0]\n",
    "    else:\n",
    "        first = min([neighbors.index(i) for i in possible_label])\n",
    "        most_common_label = neighbors[first]\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "    return most_common_label\n",
    "\n",
    "# TESTCASES 3.1\n",
    "assert knn_majority_vote(['A', 'B', 'A']) == 'A'\n",
    "assert knn_majority_vote(['B', 'B', 'A']) == 'B'\n",
    "assert knn_majority_vote(['A', 'A', 'A']) == 'A'\n",
    "assert knn_majority_vote(['A', 'B']) == 'A'\n",
    "assert knn_majority_vote(['B', 'A']) == 'B'\n",
    "print('All test cases passed!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb52633",
   "metadata": {},
   "source": [
    "### Task 3.2 - Compute KNN Regression Prediction [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ac08d",
   "metadata": {},
   "source": [
    "Now, you will implement K-Nearest Neighbors (KNN) for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e4e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 3.2\n",
    "def knn_regression(X_train, y_train, x_query, k):\n",
    "    \"\"\"\n",
    "    TODO: Implement the KNN regression algorithm.\n",
    "\n",
    "    Args:\n",
    "        X_train (list[list[float]]): Training features\n",
    "        y_train (list[float]): Target values\n",
    "        x_query (list[float]): Query point\n",
    "        k (int): Number of neighbors\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted target value by averaging the k nearest neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    prediction = 0\n",
    "\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "    training_data = [(X, y) for X, y in zip(X_train, y_train)]\n",
    "    \n",
    "    # Get k nearest neighbors\n",
    "    neighbors = get_k_nearest_neighbors(training_data, x_query, k)\n",
    "\n",
    "    # Average top k y_train \n",
    "    prediction = sum(neighbors) / k\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "    return prediction\n",
    "\n",
    "# TESTCASES 3.2\n",
    "X_train = [[1], [2], [3], [4], [5]]\n",
    "y_train = [1.1, 1.9, 3.0, 3.9, 5.1]\n",
    "x_query = [2.5]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 2), 2.45, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1], [2], [3]]\n",
    "y_train = [1, 2, 3]\n",
    "x_query = [2.1]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 1), 2, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1], [2], [3]]\n",
    "y_train = [1, 2, 3]\n",
    "x_query = [2]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 3), 2, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1, 2], [2, 3], [3, 4]]\n",
    "y_train = [10, 20, 30]\n",
    "x_query = [2, 2.5]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 2), 15.0, rel_tol=1e-5)\n",
    "\n",
    "print('All test cases passed!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352a471",
   "metadata": {},
   "source": [
    "## Task 4 - Wrapping in Classes [4 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f8599",
   "metadata": {},
   "source": [
    "### Task 4.1 -  KNN Classifier [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955d473",
   "metadata": {},
   "source": [
    "Here we combine everything into a reusable class to train your own model and make predictions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a841e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 4.1\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.training_data = []  # Will hold tuples of (feature_vector, label)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: Store the training data. DO NOT return anything!\n",
    "\n",
    "        Args:\n",
    "            X: list of feature vectors\n",
    "            y: list of labels corresponding to the feature vectors\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        self.training_data = [(feature, label) for feature, label in zip(X, y)]\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        TODO: Predict the class label for each test point in X_test.\n",
    "\n",
    "        Args:\n",
    "            X_test: list of feature vectors to classify\n",
    "\n",
    "        Returns:\n",
    "            list of predicted labels \n",
    "        \"\"\"\n",
    "    \n",
    "        predictions = []\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        for test in X_test:\n",
    "            pred = knn_majority_vote(get_k_nearest_neighbors(self.training_data, test, self.k))\n",
    "            predictions.append(pred)\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# TESTCASES 4.1\n",
    "knn = KNNClassifier(k=3)\n",
    "X_train = [[1,2],[2,3],[3,4],[5,5]]\n",
    "y_train = ['A','B','A','B']\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_test = [[1.5,2.5],[4,4]]\n",
    "assert knn.predict(X_test) == ['A', 'B']\n",
    "\n",
    "knn = KNNClassifier(k=1)\n",
    "X_train = [[1,1],[2,2],[3,3],[4,4]]\n",
    "y_train = ['A','A','B','B']\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_test = [[1.5,1.5],[3.5,3.5]]\n",
    "assert knn.predict(X_test) == ['A', 'B']\n",
    "\n",
    "print('All test cases passed!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c998d",
   "metadata": {},
   "source": [
    "### Task 4.2 - KNN Regressor [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6131",
   "metadata": {},
   "source": [
    "Similarly, we do the same for the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e537f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 4.2\n",
    "class KNNRegressor:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.training_data = []  # Will hold tuples of (feature_vector, label)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: Store the training data. DO NOT return anything!\n",
    "\n",
    "        Args:\n",
    "            X: list of feature vectors\n",
    "            y: list of labels corresponding to the feature vectors\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        self.training_data = [(feature, label) for feature, label in zip(X, y)]\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        TODO: Predict the target value for each test point in X_test\n",
    "\n",
    "        Args:\n",
    "            X_test: list of feature vectors to predict\n",
    "\n",
    "        Returns:\n",
    "            list of predicted target values \n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        for test in X_test:\n",
    "            neighbors = get_k_nearest_neighbors(self.training_data, test, self.k)\n",
    "            pred = sum(neighbors) / self.k\n",
    "            predictions.append(pred)\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "        return predictions\n",
    "\n",
    "# TESTCASES 4.2\n",
    "regressor = KNNRegressor(k=3)\n",
    "X_train = [[1], [2], [3], [4], [5]]\n",
    "y_train = [10.0, 20.0, 30.0, 40.0, 50.0]\n",
    "regressor.fit(X_train, y_train)\n",
    "X_test = [[2.5], [4.5]]\n",
    "predictions = regressor.predict(X_test)\n",
    "assert math.isclose(predictions[0], 20.0)\n",
    "assert math.isclose(predictions[1], 40.0)\n",
    "\n",
    "regressor = KNNRegressor(k=1)\n",
    "X_train = [[1, 1], [2, 2], [3, 3]]\n",
    "y_train = [10.0, 20.0, 30.0]\n",
    "regressor.fit(X_train, y_train)\n",
    "X_test = [[1.2, 1.2], [2.8, 2.8], [0.5, 0.5]]\n",
    "predictions = regressor.predict(X_test)\n",
    "assert math.isclose(predictions[0], 10.0)\n",
    "assert math.isclose(predictions[1], 30.0)\n",
    "assert math.isclose(predictions[2], 10.0)\n",
    "\n",
    "print('All test cases passed!')     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3926b78",
   "metadata": {},
   "source": [
    "## Task 5 - Practical [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8ac08",
   "metadata": {},
   "source": [
    "Train a KNN classifier on the training dataset using `scikit-learn` and tune its hyperparameters to optimize performance. We recommend that you use PCA as described in the lecture (or any other preprocessing method that you think is suitable) to also boost the model performance. You may find `make_pipeline()` useful in this task.\n",
    "\n",
    "You will get full marks if your modelling is appropriate and performs well. But remember, you **MUST NOT** use or access X_test and y_test in your code, as this defeats the purpose of a hidden test set. Any model that does so will be given 0 mark.\n",
    "\n",
    "Make sure that you have installed `scikit-learn` in your python environment. \n",
    "\n",
    "**HINT**: Set the `random_state` parameter (if exists) to a certain constant to make your model reproducible (same result on every run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d910db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV weighted-F1: 0.8215373207711668\n",
      "Best params: {'gaussianblur__sigma': np.float64(1.5), 'kneighborsclassifier__metric': 'cosine', 'kneighborsclassifier__n_neighbors': 9, 'kneighborsclassifier__weights': 'distance', 'pca__n_components': 100, 'scaler': StandardScaler()}\n",
      "Model accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# TASK 5.1\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# [Optional] TODO: Add other sklearn imports for your code \n",
    "\"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "# Load dataset\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "X = lfw_people.data  # Flattened images\n",
    "# print(len(X[0])) # 1850 dim\n",
    "y = lfw_people.target\n",
    "# print(np.unique(y, return_counts=True)) # 7 classes + imbalanced dataset\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "h, w = lfw_people.images.shape[1], lfw_people.images.shape[2]\n",
    "\n",
    "class GaussianBlur(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sigma=0.0):\n",
    "        lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "        h, w = lfw_people.images.shape[1], lfw_people.images.shape[2]\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.sigma = float(sigma)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.sigma == 0.0:\n",
    "            return X\n",
    "        X_reshaped = X.reshape(-1, self.h, self.w) # reshape to (n, h, w) from (n, h*w)\n",
    "        X_blurred = np.empty_like(X_reshaped)\n",
    "        # Apply gaussian blur filter \n",
    "        for i in range(X_reshaped.shape[0]):\n",
    "            X_blurred[i] = gaussian_filter(X_reshaped[i], sigma=self.sigma, mode='nearest')\n",
    "        return X_blurred.reshape(X.shape[0], self.h * self.w)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    TODO: Train and return a kNN classifier.\n",
    "    If using PCA, use a make_pipeline() to combine PCA and kNN.\n",
    "    When .predict() is called, the model should be able to perform any necessary transformations (like PCA) \n",
    "    on the test data automatically.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training feature vectors\n",
    "        y_train: Training labels\n",
    "\n",
    "    Returns:\n",
    "        A trained sklearn model, your model will be used to predict the labels of test data\n",
    "    \"\"\"\n",
    "\n",
    "    model = None\n",
    "\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "    gauss = GaussianBlur()\n",
    "    pca = PCA(whiten=True, svd_solver='randomized', random_state=42)\n",
    "    knn = KNeighborsClassifier()\n",
    "    pipe = make_pipeline(gauss, 'scaler', pca, knn)\n",
    "\n",
    "    param_grid = {\n",
    "        'gaussianblur__sigma': np.linspace(0.0, 3.0, 7),\n",
    "        'scaler': ['passthrough', StandardScaler(), Normalizer(norm='l2')],\n",
    "        #'pca__n_components': range(50, 251, 50), # first iter: 100, eval_acc = 0.82\n",
    "        'pca__n_components': range(50, 151, 25), # second iter: finer search after locating better param locally \n",
    "        'kneighborsclassifier__n_neighbors': range(1, 44, 2), # odd number to prevent ties + use upper bound for neighbors of sqrt(d)=43\n",
    "        'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "        'kneighborsclassifier__metric': ['minkowski', 'cosine'] # explore cosine similarity cuz high dim data\n",
    "        }\n",
    "    \n",
    "    f1_scorer = make_scorer(f1_score, average='weighted') # use F1 cuz class imbalance\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=f1_scorer, \n",
    "        cv=skf,\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "    )\n",
    "                \n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best CV weighted-F1:\", grid.best_score_)\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "    model = grid.best_estimator_\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "    return model\n",
    "\n",
    "# TESTCASES 5.1\n",
    "# Our hidden test cases will use your code to train a model to predict the labels of the test data, not necessarily on the same train-test split.\n",
    "# Note: If your model is poorly designed or performs poorly, points may be deducted.\n",
    "\n",
    "model = train_model(X_train, y_train)\n",
    "# Check if the model can predict\n",
    "predictions = model.predict(X_test)\n",
    "assert len(predictions) == len(X_test)\n",
    "accuracy_score = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf31006",
   "metadata": {},
   "source": [
    "## END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
