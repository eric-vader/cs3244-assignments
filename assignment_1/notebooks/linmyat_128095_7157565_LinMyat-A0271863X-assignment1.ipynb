{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5fdf63-0a79-4490-aa8f-3669ba1a7f58",
   "metadata": {},
   "source": [
    "# Assignment 1: k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35168e77",
   "metadata": {},
   "source": [
    "Fill in your name and student ID here.\n",
    "- Name: Lin Myat\n",
    "- Student ID: A0271863X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fadaa-a686-498a-b9c0-d56a6c8b591f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e120208",
   "metadata": {},
   "source": [
    "In this assignment, we'll implement KNN step-by-step:\n",
    "\n",
    "1. **Euclidean Distance:** Measure similarity between data points.\n",
    "2. **Find Neighbors:** Select the 'K' closest points to a query point.\n",
    "3. **Predict (Classification and Regression):** Use majority vote from neighbors and average of neighbors' values.\n",
    "4. **Build KNN Class:** Combine everything into a reusable class.\n",
    "5. **Practical**: Train a KNN classifier on the training dataset using scikit-learn.\n",
    "\n",
    "By the end, you'll understand how KNN works and how it makes predictions based on distance. Let’s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907f448",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e5041",
   "metadata": {},
   "source": [
    "3. **IMPORTANT**: Make sure that all of the cells are runnable and can compile without exception, even if the answer is incorrect. This will significantly help us in grading your solutions.\n",
    "3. For task 1 to 4, you are only allowed to use basic Python functions in your code (no `NumPy` or its equivalents), unless otherwise stated. You may reuse any functions you have defined earlier. If you are unsure whether a particular function is allowed, feel free to ask any of the TAs.\n",
    "4. For task 5, you may use the `scikit-learn` library.\n",
    "5. Your solutions will be evaluated against a set of hidden test cases to prevent hardcoding of the answer. You may assume that the test cases are always valid and does not require exception or input mismatch handling. Partial marks may be given for partially correct solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078789f1",
   "metadata": {},
   "source": [
    "## Task 1 - Compute Euclidean Distance [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef572c3-37d7-4cb1-a9b3-e3c5c35f2586",
   "metadata": {},
   "source": [
    "To find the nearest neighbors, we first need a distance measure to determine how **close** two data points are. \n",
    "\n",
    "A possible distance measure is **Euclidean distance**—the straight-line distance between points $\\mathbf{p} = [p_1, p_2, ..., p_m]$ and $\\mathbf{q} = [q_1, q_2, ..., q_m]$ in $m$ dimensions:\n",
    "\n",
    "$$\n",
    "d_\\text{euclidean}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{m} (p_i - q_i)^2}\n",
    "$$\n",
    "\n",
    "Implement the function calculating euclidean distance using `math.sqrt()`, without the use of `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea197b46-1d86-4dbd-8474-36d62b8291d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 1\n",
    "import math \n",
    "\n",
    "def euclidean_distance(vec_p, vec_q):\n",
    "    \"\"\"\n",
    "    TODO: Write a function to compute distance between two vectors.\n",
    "    Call the math.sqrt() function to compute the square root of the sum of squared differences.\n",
    "\n",
    "    Args:\n",
    "        vec_p: List or tuple p, with a list of m numbers\n",
    "        vec_q: List or tuple q, with a list of m numbers\n",
    "\n",
    "    Returns:\n",
    "        A float representing the Euclidean distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    if len(vec_p) != len(vec_q):\n",
    "        raise ValueError(\"vec_p and vec_q must have the same length\")\n",
    "    return math.sqrt(sum((xi - yi) ** 2 for xi, yi in zip(vec_p, vec_q)))\n",
    "\n",
    "# TESTCASES 1\n",
    "assert math.isclose(euclidean_distance([1, 2, 3], [4, 5, 6]), 5.196152422706632, rel_tol=1e-5)\n",
    "assert math.isclose(euclidean_distance([5.5, 5.5], [5.5, 5.5]), 0.0, rel_tol=1e-5)\n",
    "assert math.isclose(euclidean_distance([-6], [-6]), 0.0, rel_tol=1e-5)\n",
    "print('All test cases passed!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127cc23a",
   "metadata": {},
   "source": [
    "## Task 2 - Get the K Nearest Neighbors [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b419ad",
   "metadata": {},
   "source": [
    "Now that we can measure distance, let’s use that to find the ```k``` closest training points to a given test point. If there are multiple points with the same distance, we keep the ones that appear first in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82ccfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 2\n",
    "def get_k_nearest_neighbors(training_data, test_point, k):\n",
    "    \"\"\"\n",
    "    TODO: Return the k nearest neighbors to the test_point.\n",
    "\n",
    "    Args:\n",
    "        training_data: list of tuples [(feature_vector, label), ...]\n",
    "        test_point: list of numbers (the point we're classifying)\n",
    "        k: number of neighbors to consider\n",
    "        \n",
    "    Returns:\n",
    "        list of labels of the k nearest neighbors in the correct order\n",
    "    \"\"\"\n",
    "\n",
    "    k_neighbors = []\n",
    "    \n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "\n",
    "    # compute the distance from the test point to each training example\n",
    "    distances = []\n",
    "    for (features, label) in training_data:\n",
    "        dist = euclidean_distance(features, test_point)\n",
    "        distances.append((dist, label))\n",
    "\n",
    "    # sort by distance and return the labels of the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_neighbors = [label for (_, label) in distances[:k]]\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    return k_neighbors\n",
    "\n",
    "# TESTCASES 2.1\n",
    "training_data = [\n",
    "    ([1, 2], 'A'),\n",
    "    ([2, 3], 'B'),\n",
    "    ([3, 4], 'A'),\n",
    "    ([5, 5], 'B')\n",
    "]\n",
    "\n",
    "assert get_k_nearest_neighbors(training_data, [1.5, 2.5], k=2) == ['A', 'B']\n",
    "assert get_k_nearest_neighbors(training_data, [4, 4], k=1) == ['A']\n",
    "assert get_k_nearest_neighbors(training_data, [0, 0], k=3) == ['A', 'B', 'A']\n",
    "print('All test cases passed!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f416626",
   "metadata": {},
   "source": [
    "## Task 3 - Prediction [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73ccfa",
   "metadata": {},
   "source": [
    "### Task 3.1 - Compute Majority Voting [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb1894",
   "metadata": {},
   "source": [
    "Once we have the `k` nearest neighbors, we need to decide the final label, which is the label that appears the most frequently. If there is a tie, return the label that appears first in the input list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d69d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 3.1\n",
    "def knn_majority_vote(neighbors):\n",
    "    \"\"\"\n",
    "    TODO: Return the most common label in neighbors.\n",
    "\n",
    "    Args:\n",
    "        neighbors: list of labels\n",
    "\n",
    "    Returns:\n",
    "        The label that appears most frequently\n",
    "        If there's a tie, return the label that appears first\n",
    "    \"\"\"\n",
    "    \n",
    "    most_common_label = None\n",
    "\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "    label_counts = {}\n",
    "    for label in neighbors:\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "    max_count = 0\n",
    "\n",
    "    for label in neighbors:\n",
    "        count = label_counts[label]\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            most_common_label = label\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    return most_common_label\n",
    "\n",
    "# TESTCASES 3.1\n",
    "assert knn_majority_vote(['A', 'B', 'A']) == 'A'\n",
    "assert knn_majority_vote(['B', 'B', 'A']) == 'B'\n",
    "assert knn_majority_vote(['A', 'A', 'A']) == 'A'\n",
    "assert knn_majority_vote(['A', 'B']) == 'A'\n",
    "assert knn_majority_vote(['B', 'A']) == 'B'\n",
    "assert knn_majority_vote(['B', 'A', 'B', 'A']) == 'B'\n",
    "assert knn_majority_vote(['A', 'B', 'A', 'B']) == 'A'\n",
    "print('All test cases passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb52633",
   "metadata": {},
   "source": [
    "### Task 3.2 - Compute KNN Regression Prediction [1 Point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ac08d",
   "metadata": {},
   "source": [
    "Now, you will implement K-Nearest Neighbors (KNN) for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e4e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 3.2\n",
    "def knn_regression(X_train, y_train, x_query, k):\n",
    "    \"\"\"\n",
    "    TODO: Implement the KNN regression algorithm.\n",
    "\n",
    "    Args:\n",
    "        X_train (list[list[float]]): Training features\n",
    "        y_train (list[float]): Target values\n",
    "        x_query (list[float]): Query point\n",
    "        k (int): Number of neighbors\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted target value by averaging the k nearest neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    prediction = 0\n",
    "\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "    # Compute the distance from the query point to each training example\n",
    "    distances = []\n",
    "    for i, features in enumerate(X_train):\n",
    "        dist = euclidean_distance(features, x_query)\n",
    "        distances.append((dist, i))\n",
    "\n",
    "    # Sort by distance and select the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest = distances[:k]\n",
    "\n",
    "    # Compute the average of the target values of the k nearest neighbors\n",
    "    prediction = sum(y_train[i] for _, i in k_nearest) / k\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# TESTCASES 3.2\n",
    "import math\n",
    "\n",
    "X_train = [[1], [2], [3], [4], [5]]\n",
    "y_train = [1.1, 1.9, 3.0, 3.9, 5.1]\n",
    "x_query = [2.5]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 2), 2.45, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1], [2], [3]]\n",
    "y_train = [1, 2, 3]\n",
    "x_query = [2.1]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 1), 2, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1], [2], [3]]\n",
    "y_train = [1, 2, 3]\n",
    "x_query = [2]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 3), 2, rel_tol=1e-5)\n",
    "\n",
    "X_train = [[1, 2], [2, 3], [3, 4]]\n",
    "y_train = [10, 20, 30]\n",
    "x_query = [2, 2.5]\n",
    "assert math.isclose(knn_regression(X_train, y_train, x_query, 2), 15.0, rel_tol=1e-5)\n",
    "\n",
    "print('All test cases passed!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352a471",
   "metadata": {},
   "source": [
    "## Task 4 - Wrapping in Classes [4 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f8599",
   "metadata": {},
   "source": [
    "### Task 4.1 -  KNN Classifier [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955d473",
   "metadata": {},
   "source": [
    "Here we combine everything into a reusable class to train your own model and make predictions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a841e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 4.1\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.training_data = []  # Will hold tuples of (feature_vector, label)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: Store the training data. DO NOT return anything!\n",
    "\n",
    "        Args:\n",
    "            X: list of feature vectors\n",
    "            y: list of labels corresponding to the feature vectors\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        # Store the training data\n",
    "        self.training_data = list(zip(X, y))\n",
    "        # outputs [([1, 2], 'A'), ([2, 3], 'B'), ([3, 4], 'A'), ([5, 5], 'B')]\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        TODO: Predict the class label for each test point in X_test.\n",
    "\n",
    "        Args:\n",
    "            X_test: list of feature vectors to classify\n",
    "\n",
    "        Returns:\n",
    "            list of predicted labels \n",
    "        \"\"\"\n",
    "    \n",
    "        predictions = []\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        # For each test point, find the k nearest neighbors and perform majority voting\n",
    "        for x in X_test:\n",
    "            # Compute distances from the test point to all training points\n",
    "            distances = []\n",
    "            for (x_train, label) in self.training_data:\n",
    "                dist = euclidean_distance(x_train, x)\n",
    "                distances.append((dist, label))\n",
    "\n",
    "            # Sort by distance and select the k nearest neighbors\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            k_nearest = distances[:self.k]\n",
    "\n",
    "            # Perform majority voting\n",
    "            vote = knn_majority_vote([label for _, label in k_nearest])\n",
    "            predictions.append(vote)\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# TESTCASES 4.1\n",
    "knn = KNNClassifier(k=3)\n",
    "X_train = [[1,2],[2,3],[3,4],[5,5]]\n",
    "y_train = ['A','B','A','B']\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_test = [[1.5,2.5],[4,4]]\n",
    "assert knn.predict(X_test) == ['A', 'B']\n",
    "\n",
    "knn = KNNClassifier(k=1)\n",
    "X_train = [[1,1],[2,2],[3,3],[4,4]]\n",
    "y_train = ['A','A','B','B']\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_test = [[1.5,1.5],[3.5,3.5]]\n",
    "assert knn.predict(X_test) == ['A', 'B']\n",
    "\n",
    "print('All test cases passed!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c998d",
   "metadata": {},
   "source": [
    "### Task 4.2 - KNN Regressor [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c6131",
   "metadata": {},
   "source": [
    "Similarly, we do the same for the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e537f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "# TASK 4.2\n",
    "class KNNRegressor:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.training_data = []  # Will hold tuples of (feature_vector, label)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: Store the training data. DO NOT return anything!\n",
    "\n",
    "        Args:\n",
    "            X: list of feature vectors\n",
    "            y: list of labels corresponding to the feature vectors\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        self.training_data = list(zip(X, y))\n",
    "        # print(self.training_data)\n",
    "        # outputs are [([1], 10.0), ([2], 20.0), ([3], 30.0), ([4], 40.0), ([5], 50.0)]\n",
    "        # [([1, 1], 10.0), ([2, 2], 20.0), ([3, 3], 30.0)]\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        TODO: Predict the target value for each test point in X_test\n",
    "\n",
    "        Args:\n",
    "            X_test: list of feature vectors to predict\n",
    "\n",
    "        Returns:\n",
    "            list of predicted target values \n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        # For each test point, find the k nearest neighbors and predict the target value\n",
    "        for x in X_test:\n",
    "            # Compute distances from the test point to all training points\n",
    "            distances = []\n",
    "            for (x_train, label) in self.training_data:\n",
    "                dist = euclidean_distance(x_train, x)\n",
    "                distances.append((dist, label))\n",
    "\n",
    "            # Sort by distance and select the k nearest neighbors\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            k_nearest = distances[:self.k]\n",
    "\n",
    "            # Predict the target value by averaging the k nearest neighbors\n",
    "            prediction = sum(label for _, label in k_nearest) / self.k\n",
    "            predictions.append(prediction)\n",
    "        \"\"\" YOUR CODE ENDS HERE \"\"\" \n",
    "\n",
    "        return predictions\n",
    "\n",
    "# TESTCASES 4.2\n",
    "import math\n",
    "\n",
    "regressor = KNNRegressor(k=3)\n",
    "X_train = [[1], [2], [3], [4], [5]]\n",
    "y_train = [10.0, 20.0, 30.0, 40.0, 50.0]\n",
    "regressor.fit(X_train, y_train)\n",
    "X_test = [[2.5], [4.5]]\n",
    "predictions = regressor.predict(X_test)\n",
    "assert math.isclose(predictions[0], 20.0)\n",
    "assert math.isclose(predictions[1], 40.0)\n",
    "\n",
    "regressor = KNNRegressor(k=1)\n",
    "X_train = [[1, 1], [2, 2], [3, 3]]\n",
    "y_train = [10.0, 20.0, 30.0]\n",
    "regressor.fit(X_train, y_train)\n",
    "X_test = [[1.2, 1.2], [2.8, 2.8], [0.5, 0.5]]\n",
    "predictions = regressor.predict(X_test)\n",
    "assert math.isclose(predictions[0], 10.0)\n",
    "assert math.isclose(predictions[1], 30.0)\n",
    "assert math.isclose(predictions[2], 10.0)\n",
    "\n",
    "print('All test cases passed!')     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3926b78",
   "metadata": {},
   "source": [
    "## Task 5 - Practical [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8ac08",
   "metadata": {},
   "source": [
    "Train a KNN classifier on the training dataset using `scikit-learn` and tune its hyperparameters to optimize performance. We recommend that you use PCA as described in the lecture (or any other preprocessing method that you think is suitable) to also boost the model performance. You may find `make_pipeline()` useful in this task.\n",
    "\n",
    "You will get full marks if your modelling is appropriate and performs well. But remember, you **MUST NOT** use or access X_test and y_test in your code, as this defeats the purpose of a hidden test set. Any model that does so will be given 0 mark.\n",
    "\n",
    "Make sure that you have installed `scikit-learn` in your python environment. \n",
    "\n",
    "**HINT**: Set the `random_state` parameter (if exists) to a certain constant to make your model reproducible (same result on every run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d910db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "    # TASK 5.1\n",
    "    from sklearn.datasets import fetch_lfw_people\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    # [Optional] TODO: Add other sklearn imports for your code \n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "    X = lfw_people.data  # Flattened images\n",
    "    y = lfw_people.target\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    def train_model(X_train, y_train):\n",
    "        \"\"\"\n",
    "        TODO: Train and return a kNN classifier.\n",
    "        If using PCA, use a make_pipeline() to combine PCA and kNN.\n",
    "        When .predict() is called, the model should be able to perform any necessary transformations (like PCA) \n",
    "        on the test data automatically.\n",
    "\n",
    "        Args:\n",
    "            X_train: Training feature vectors\n",
    "            y_train: Training labels\n",
    "\n",
    "        Returns:\n",
    "            A trained sklearn model, your model will be used to predict the labels of test data\n",
    "        \"\"\"\n",
    "\n",
    "        model = None\n",
    "\n",
    "        \"\"\" YOUR CODE STARTS HERE \"\"\" \n",
    "        # Create a pipeline with StandardScaler, PCA, and KNeighborsClassifier\n",
    "        pipeline = make_pipeline(StandardScaler(), PCA(random_state = 42), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "        param_grid = {\n",
    "            'kneighborsclassifier__n_neighbors': [3, 5, 7, 9],\n",
    "            'pca__n_components': [100, 150, 200],\n",
    "            \"kneighborsclassifier__metric\": [\"euclidean\", \"manhattan\"]\n",
    "        }\n",
    "\n",
    "        grid = GridSearchCV(estimator = pipeline, param_grid = param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # TESTCASES 5.1\n",
    "    # Our hidden test cases will use your code to train a model to predict the labels of the test data, not necessarily on the same train-test split.\n",
    "    # Note: If your model is poorly designed or performs poorly, points may be deducted.\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    # Check if the model can predict\n",
    "    predictions = model.predict(X_test)\n",
    "    assert len(predictions) == len(X_test)\n",
    "    accuracy_score = model.score(X_test, y_test)\n",
    "    print(f\"Model accuracy: {accuracy_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf31006",
   "metadata": {},
   "source": [
    "## END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
